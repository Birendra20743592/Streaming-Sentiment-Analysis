{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for TCP connection...\n",
      "Connected to : ('127.0.0.1', 60344)\n",
      "https://stream.twitter.com/1.1/statuses/filter.json?language=en&locations=-180,-60,180,60&track=# <Response [200]>\n",
      "Starting getting tweets.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import socket\n",
    "import sys\n",
    "import requests\n",
    "import requests_oauthlib\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Replace the values below with yours\n",
    "# Replace the values below with yours\n",
    "ACCESS_TOKEN = 'YOUR ACCESS TOKEN'\n",
    "ACCESS_SECRET = 'YOUR ACCESS SECRET'\n",
    "CONSUMER_KEY = 'YOUR CONSUMER KEY'\n",
    "CONSUMER_SECRET = 'YOUR CONSUMER SECRET'\n",
    "my_auth = requests_oauthlib.OAuth1(CONSUMER_KEY, CONSUMER_SECRET,ACCESS_TOKEN, ACCESS_SECRET)\n",
    "#my_auth = requests_oauthlib.OAuth1(CONSUMER_KEY, CONSUMER_SECRET,ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "list2=[]\n",
    "def trending_hash_tag(row):\n",
    "    global list2\n",
    "    C = Counter(list2)\n",
    "    string = str(row[\"Text\"])\n",
    "    tag = re.findall(r\"#(\\w+)\", string)\n",
    "    dict1={}\n",
    "    if len(tag)>0:\n",
    "        for element in tag:\n",
    "            dict1[element]= C[element]\n",
    "        trending_hashtag= sorted(dict1)[0]\n",
    "    else:\n",
    "        trending_hashtag=\"\"\n",
    "    return trending_hashtag\n",
    "    \n",
    "list1 =[]\n",
    "def hash_tag(row):\n",
    "    global list1\n",
    "    string = str(row[\"Text\"])\n",
    "    tag = re.findall(r\"#(\\w+)\", string)\n",
    "    list1.append(tag) \n",
    "    return \" \".join(tag)\n",
    "tweet_list =[]\n",
    "def save_tweet(tweet):\n",
    "    global tweet_list\n",
    "    tweet = tweet.split(\"*////*\")\n",
    "    score = analyser.polarity_scores(tweet[4])[\"compound\"]\n",
    "    if score >0.33:\n",
    "        sentiment = \"positive\"\n",
    "    elif score <-0.33:\n",
    "        sentiment = \"negative\"\n",
    "    else:\n",
    "        sentiment = \"neutral\"\n",
    "    tweet.append(sentiment)\n",
    "    tweet_list = tweet_list+[tweet]\n",
    "    data_frame =pd.DataFrame(tweet_list,columns=['Time','longitude', 'latitude','place', \"Text\", \"Sentiment\"])\n",
    "    data_frame[\"hashstag\"] = data_frame.apply(hash_tag,axis =1)\n",
    "    data_frame[\"Trending hashtag\"]= data_frame.apply(trending_hash_tag,axis=1)\n",
    "    #print(tweet)\n",
    "    #data_frame.append(tweet, ignore_index = True)\n",
    "    data_frame.to_csv(\"Tweet_data.csv\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def send_tweets_to_spark(conn,http_resp):\n",
    "    for line in http_resp.iter_lines():\n",
    "        try:\n",
    "            #conn, addr = new_socket.accept()\n",
    "            full_tweet = json.loads(line)\n",
    "            # refer https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object.html for details\n",
    "            tweet_text = str(full_tweet[\"created_at\"])+\"*////*\"+str(full_tweet[\"coordinates\"][\"coordinates\"][0])+\"*////*\"+str(full_tweet[\"coordinates\"][\"coordinates\"][1])+\"*////*\"+full_tweet[\"place\"][\"name\"]+\"*////*\"+full_tweet[\"text\"]\n",
    "            #tweet_text  = full_tweet['text']\n",
    "            #row = [ user, text, latitude, longitude, gender ]\n",
    "            data = tweet_text+'\\n'\n",
    "            #save_tweet(tweet_text)\n",
    "            #print(\"Tweet Text: \" + tweet_text)\n",
    "            #print (\"------------------------------------------\")\n",
    "            conn.send(data.encode('ascii','ignore'))\n",
    "            #conn.close()\n",
    "        except:\n",
    "            e = sys.exc_info()[0]\n",
    "            #print(\"Error: %s\" % e)\n",
    "\n",
    "\n",
    "def get_tweets():\n",
    "    url = 'https://stream.twitter.com/1.1/statuses/filter.json'\n",
    "    query_data = [('language', 'en'), ('locations', '-180,-60,180,60'),('track','#')]\n",
    "    #query_data = [('language', 'en')]\n",
    "    #query_data = [('locations', '-130,-20,100,50'), ('track', '#')]\n",
    "    query_url = url + '?' + '&'.join([str(t[0]) + '=' + str(t[1]) for t in query_data])\n",
    "    response = requests.get(query_url, auth=my_auth, stream=True)\n",
    "    print(query_url, response)\n",
    "    return response\n",
    "\n",
    "\n",
    "TCP_IP = \"localhost\"\n",
    "TCP_PORT = 5000\n",
    "conn = None\n",
    "s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "s.bind((TCP_IP, TCP_PORT))\n",
    "s.listen(1)\n",
    "print(\"Waiting for TCP connection...\")\n",
    "conn, addr = s.accept()\n",
    "print(\"Connected to :\",addr)\n",
    "resp = get_tweets()\n",
    "print(\"Starting getting tweets.\")\n",
    "send_tweets_to_spark(conn,resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
